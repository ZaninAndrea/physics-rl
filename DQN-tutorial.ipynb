{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/andrea/.local/lib/python3.11/site-packages/tensorflow/python/ops/distributions/distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /Users/andrea/.local/lib/python3.11/site-packages/tensorflow/python/ops/distributions/bernoulli.py:165: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import base64\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import py_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.utils import common\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 20000  # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 100  # @param {type:\"integer\"}\n",
    "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}\n",
    "n_step_update = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAGQAlgDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD3+iiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKhu7j7JZT3G3d5UbPtzjOBnFct/wnP8A1Dv/ACP/APY1nOrCGkmaQpTnrFHX0VT0u+/tLTorvy/L8zPybs4wSOv4Vcq001dENNOzCiiimIKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigChrZ26Hen/pkw/SvMK9H8Tkr4duyCQcKOP8AeFecV5uNfvpeR34Re4z0fwv/AMi5af8AA/8A0Nq16ztBQJoVmAAB5YPHvzWjXfSVoJeRx1NZsKKKKsgKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDH8Uf8AIuXX/AP/AEMV5zXofis48PzD1ZR/48K88rzMZ/EXoehhPg+Z6jpAxo1iP+mCH/x0VdqnpP8AyBrH/r3j/wDQRVyvRh8KOGXxMKKKKokKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDnfGbsuixgHAadQfcYY/wBBXB13fjT/AJA8P/XwP/QWrhK8rF/xD0sL/DPWLOMRWUEajCpGqgfQVNSKNqAegxS16i0R5rCiiimAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHM+NT/AMSy3X1mz/46a4eux8cSERWUfG1mdj+GP8a5K3jE1zFEc4dwpx7mvKxWtVo9LD6U0z1qiiivVPNCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAOQ8c/8uH/AG0/9lrmtMG7VbNfWdB/48K6Pxwf3lkvoHP8q57Sf+QzY/8AXxH/AOhCvKr/AMd/I9Kj/B+89Sooor1TzQooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDiPG0mdRt4sfdh3Z+pP+FY+iR+brlkucYmVvyOf6VqeNP8AkMw/9e6/+hNVHw0N3iG0Hux/8dNeVU1r/M9KGlH5HpNFFFeqeaFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRXP+NvE/wDwh3hC+1/7H9s+y+X+483y926RU+9g4xuz07UAdBRXz/8A8NNf9Sj/AOVL/wC1Uf8ADTX/AFKP/lS/+1UAeieMznWkHpAo/Vqq+F/+RjtP+B/+gNWBaeLT4zsINdeyWxWYFVh87zMBWK5LbV7g9qh1Lxcngq2TXDaG98pwiwiXYGLAj72DjAyeh6fjXltN17+Z6SsqNvI9ror5/wD+Gmv+pR/8qX/2qj/hpr/qUf8Aypf/AGqvUPNPoCis/QtT/tvw9pmreT5P260iufK3btm9A23OBnGcZwK0KACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKK5/wCx+MP+g7of/gmm/wDkqj7H4w/6Duh/+Cab/wCSqAOgorn/ALH4w/6Duh/+Cab/AOSqPsfjD/oO6H/4Jpv/AJKoA6Ciuf8AsfjD/oO6H/4Jpv8A5Ko+x+MP+g7of/gmm/8AkqgDoKK5/wCx+MP+g7of/gmm/wDkqj7H4w/6Duh/+Cab/wCSqAOgorn/ALH4w/6Duh/+Cab/AOSqPsfjD/oO6H/4Jpv/AJKoA6Ciuf8AsfjD/oO6H/4Jpv8A5Ko+x+MP+g7of/gmm/8AkqgDoKK5/wCx+MP+g7of/gmm/wDkqj7H4w/6Duh/+Cab/wCSqAOgorn/ALH4w/6Duh/+Cab/AOSqPsfjD/oO6H/4Jpv/AJKoA6Ciuf8AsfjD/oO6H/4Jpv8A5Ko+x+MP+g7of/gmm/8AkqgDoKK5/wCx+MP+g7of/gmm/wDkqj7H4w/6Duh/+Cab/wCSqAOgorn/ALH4w/6Duh/+Cab/AOSqPsfjD/oO6H/4Jpv/AJKoA6Ciuf8AsfjD/oO6H/4Jpv8A5Ko+x+MP+g7of/gmm/8AkqgDoKK5/wCx+MP+g7of/gmm/wDkqj7H4w/6Duh/+Cab/wCSqAOgorn/ALH4w/6Duh/+Cab/AOSqPsfjD/oO6H/4Jpv/AJKoA6Ciuf8AsfjD/oO6H/4Jpv8A5Ko+x+MP+g7of/gmm/8AkqgDoKK5/wCx+MP+g7of/gmm/wDkqj7H4w/6Duh/+Cab/wCSqAOgrz/42/8AJIdd/wC3f/0ojroPsfjD/oO6H/4Jpv8A5Krh/i/beJI/hbrLX+q6VPajyN8cGmSRO37+PGGM7Ac4/hPpx1oA+WKKKKAPavApY+CtOBzgeZj/AL+NVH4kyMvhRVydrXSD8cMf6V5/Y+MNd03T4rG0vvLtos7E8mNsZJJ5K56k1HqnijWdZs1tNQvPOgRxIF8pF+YAjOVAPQmul4hOj7Pl/rv6hbW9zHooormA+3/An/JPPDX/AGCrX/0UtdBXB+C7XxU3gXw81vrOjRwHTLYxpJpMrsq+UuAWFyATjvgZ9BW59j8Yf9B3Q/8AwTTf/JVAHQUVz/2Pxh/0HdD/APBNN/8AJVH2Pxh/0HdD/wDBNN/8lUAdBRXP/Y/GH/Qd0P8A8E03/wAlUfY/GH/Qd0P/AME03/yVQB0FFc/9j8Yf9B3Q/wDwTTf/ACVR9j8Yf9B3Q/8AwTTf/JVAHQUVz/2Pxh/0HdD/APBNN/8AJVH2Pxh/0HdD/wDBNN/8lUAdBRXP/Y/GH/Qd0P8A8E03/wAlUfY/GH/Qd0P/AME03/yVQB0FFc/9j8Yf9B3Q/wDwTTf/ACVR9j8Yf9B3Q/8AwTTf/JVAHQUVz/2Pxh/0HdD/APBNN/8AJVH2Pxh/0HdD/wDBNN/8lUAdBRXP/Y/GH/Qd0P8A8E03/wAlUfY/GH/Qd0P/AME03/yVQB0FFc/9j8Yf9B3Q/wDwTTf/ACVR9j8Yf9B3Q/8AwTTf/JVAHQUVz/2Pxh/0HdD/APBNN/8AJVH2Pxh/0HdD/wDBNN/8lUAdBRXP/Y/GH/Qd0P8A8E03/wAlUfY/GH/Qd0P/AME03/yVQB0FFc/9j8Yf9B3Q/wDwTTf/ACVR9j8Yf9B3Q/8AwTTf/JVAHQUVz/2Pxh/0HdD/APBNN/8AJVH2Pxh/0HdD/wDBNN/8lUAdBRXP/Y/GH/Qd0P8A8E03/wAlUfY/GH/Qd0P/AME03/yVQB0FFc/9j8Yf9B3Q/wDwTTf/ACVR9j8Yf9B3Q/8AwTTf/JVAHQUVz/2Pxh/0HdD/APBNN/8AJVH2Pxh/0HdD/wDBNN/8lUAdBRXP/Y/GH/Qd0P8A8E03/wAlUUAdBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAV5/wDG3/kkOu/9u/8A6UR16BWP4p8N2fi7w5d6HfyTx2t1s3vAwDja6uMEgjqo7UAfDFFfT/8Awzj4P/6CWuf9/wCH/wCNUf8ADOPg/wD6CWuf9/4f/jVAHzBRX0//AMM4+D/+glrn/f8Ah/8AjVH/AAzj4P8A+glrn/f+H/41QB8wUV9P/wDDOPg//oJa5/3/AIf/AI1R/wAM4+D/APoJa5/3/h/+NUAegeBP+SeeGv8AsFWv/opa6Cqek6bDo2jWOl27SNBZW8dvG0hBYqihQTgAZwPQVcoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA/9k=",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=600x400>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_name = 'CartPole-v0'\n",
    "env = suite_gym.load(env_name)\n",
    "env.reset()\n",
    "PIL.Image.fromarray(env.render())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Spec:\n",
      "BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name='observation', minimum=[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], maximum=[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38])\n",
      "Reward Spec:\n",
      "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n",
      "Action Spec:\n",
      "BoundedArraySpec(shape=(), dtype=dtype('int64'), name='action', minimum=0, maximum=1)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print('Observation Spec:')\n",
    "print(env.time_step_spec().observation)\n",
    "print('Reward Spec:')\n",
    "print(env.time_step_spec().reward)\n",
    "print('Action Spec:')\n",
    "print(env.action_spec())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([-0.04672298,  0.01595005, -0.01526626, -0.008935  ], dtype=float32),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(0, dtype=int32)})\n",
      "Next time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([-0.04640398,  0.21128757, -0.01544496, -0.30639526], dtype=float32),\n",
      " 'reward': array(1., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n"
     ]
    }
   ],
   "source": [
    "time_step = env.reset()\n",
    "print('Time step:')\n",
    "print(time_step)\n",
    "\n",
    "action = np.array(1, dtype=np.int32)\n",
    "\n",
    "next_time_step = env.step(action)\n",
    "print('Next time step:')\n",
    "print(next_time_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_py_env = suite_gym.load(env_name)\n",
    "eval_py_env = suite_gym.load(env_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_params = (100, 50)\n",
    "action_tensor_spec = tensor_spec.from_spec(env.action_spec())\n",
    "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
    "\n",
    "# Define a helper function to create Dense layers configured with the right\n",
    "# activation and kernel initializer.\n",
    "\n",
    "\n",
    "def dense_layer(num_units):\n",
    "  return tf.keras.layers.Dense(\n",
    "      num_units,\n",
    "      activation=tf.keras.activations.relu,\n",
    "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "          scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
    "\n",
    "\n",
    "# QNetwork consists of a sequence of Dense layers followed by a dense layer\n",
    "# with `num_actions` units to generate one q_value per available action as\n",
    "# its output.\n",
    "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
    "q_values_layer = tf.keras.layers.Dense(\n",
    "    num_actions,\n",
    "    activation=None,\n",
    "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
    "        minval=-0.03, maxval=0.03),\n",
    "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
    "q_net = sequential.Sequential(dense_layers + [q_values_layer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy\n",
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=())"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_environment = tf_py_environment.TFPyEnvironment(\n",
    "    suite_gym.load('CartPole-v0'))\n",
    "time_step = example_environment.reset()\n",
    "random_policy.action(time_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "# See also the metrics module for standard implementations of different metrics.\n",
    "# https://github.com/tensorflow/agents/tree/master/tf_agents/metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.6"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_avg_return(eval_env, random_policy, num_eval_episodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_max_length)\n",
    "\n",
    "\n",
    "def collect_step(environment, policy):\n",
    "  time_step = environment.current_time_step()\n",
    "  action_step = policy.action(time_step)\n",
    "  next_time_step = environment.step(action_step.action)\n",
    "  traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "  # Add trajectory to the replay buffer\n",
    "  replay_buffer.add_batch(traj)\n",
    "\n",
    "\n",
    "for _ in range(initial_collect_steps):\n",
    "  collect_step(train_env, random_policy)\n",
    "\n",
    "# This loop is so common in RL, that we provide standard implementations of\n",
    "# these. For more details see the drivers module.\n",
    "\n",
    "# Dataset generates trajectories with shape [BxTx...] where\n",
    "# T = n_step_update + 1.\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, sample_batch_size=batch_size,\n",
    "    num_steps=n_step_update ).prefetch(3)\n",
    "\n",
    "iterator = iter(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.80\n",
      "Iteration  1\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.30\n",
      "Iteration  2\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.70\n",
      "Iteration  3\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.30\n",
      "Iteration  4\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.50\n",
      "Iteration  5\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.30\n",
      "Iteration  6\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.30\n",
      "Iteration  7\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.40\n",
      "Iteration  8\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.20\n",
      "Iteration  9\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.30\n",
      "Iteration  10\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.50\n",
      "Iteration  11\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.40\n",
      "Iteration  12\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.20\n",
      "Iteration  13\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.30\n",
      "Iteration  14\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.50\n",
      "Iteration  15\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.20\n",
      "Iteration  16\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.20\n",
      "Iteration  17\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.30\n",
      "Iteration  18\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.20\n",
      "Iteration  19\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.40\n",
      "Iteration  20\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.50\n",
      "Iteration  21\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.20\n",
      "Iteration  22\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.60\n",
      "Iteration  23\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.40\n",
      "Iteration  24\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.00\n",
      "Iteration  25\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.20\n",
      "Iteration  26\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.40\n",
      "Iteration  27\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.10\n",
      "Iteration  28\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.20\n",
      "Iteration  29\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 8.90\n",
      "Iteration  30\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.00\n",
      "Iteration  31\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.20\n",
      "Iteration  32\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.30\n",
      "Iteration  33\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.30\n",
      "Iteration  34\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.50\n",
      "Iteration  35\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.20\n",
      "Iteration  36\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.50\n",
      "Iteration  37\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.40\n",
      "Iteration  38\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.40\n",
      "Iteration  39\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n",
      "step = 0: Average Return = 9.80\n",
      "Iteration  40\n",
      "<class 'tf_agents.trajectories.trajectory.Trajectory'>\n",
      "step = 0: loss = None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mstep = \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m: loss = \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(step, train_loss))\n\u001b[1;32m     34\u001b[0m \u001b[39mif\u001b[39;00m step \u001b[39m%\u001b[39m eval_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 35\u001b[0m   avg_return \u001b[39m=\u001b[39m compute_avg_return(eval_env, agent\u001b[39m.\u001b[39;49mpolicy, num_eval_episodes)\n\u001b[1;32m     36\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mstep = \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m: Average Return = \u001b[39m\u001b[39m{1:.2f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(step, avg_return))\n\u001b[1;32m     37\u001b[0m   returns\u001b[39m.\u001b[39mappend(avg_return)\n",
      "Cell \u001b[0;32mIn[38], line 10\u001b[0m, in \u001b[0;36mcompute_avg_return\u001b[0;34m(environment, policy, num_episodes)\u001b[0m\n\u001b[1;32m      7\u001b[0m episode_return \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m time_step\u001b[39m.\u001b[39mis_last():\n\u001b[0;32m---> 10\u001b[0m   action_step \u001b[39m=\u001b[39m policy\u001b[39m.\u001b[39;49maction(time_step)\n\u001b[1;32m     11\u001b[0m   time_step \u001b[39m=\u001b[39m environment\u001b[39m.\u001b[39mstep(action_step\u001b[39m.\u001b[39maction)\n\u001b[1;32m     12\u001b[0m   episode_return \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m time_step\u001b[39m.\u001b[39mreward\n",
      "File \u001b[0;32m~/miniforge3/envs/tfagents/lib/python3.11/site-packages/tf_agents/policies/tf_policy.py:324\u001b[0m, in \u001b[0;36mTFPolicy.action\u001b[0;34m(self, time_step, policy_state, seed)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_automatic_state_reset:\n\u001b[1;32m    323\u001b[0m   policy_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_reset_state(time_step, policy_state)\n\u001b[0;32m--> 324\u001b[0m step \u001b[39m=\u001b[39m action_fn(time_step\u001b[39m=\u001b[39;49mtime_step, policy_state\u001b[39m=\u001b[39;49mpolicy_state, seed\u001b[39m=\u001b[39;49mseed)\n\u001b[1;32m    326\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclip_action\u001b[39m(action, action_spec):\n\u001b[1;32m    327\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(action_spec, tensor_spec\u001b[39m.\u001b[39mBoundedTensorSpec):\n",
      "File \u001b[0;32m~/miniforge3/envs/tfagents/lib/python3.11/site-packages/tf_agents/utils/common.py:188\u001b[0m, in \u001b[0;36mfunction_in_tf1.<locals>.maybe_wrap.<locals>.with_check_resource_vars\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m check_tf1_allowed()\n\u001b[1;32m    185\u001b[0m \u001b[39mif\u001b[39;00m has_eager_been_enabled():\n\u001b[1;32m    186\u001b[0m   \u001b[39m# We're either in eager mode or in tf.function mode (no in-between); so\u001b[39;00m\n\u001b[1;32m    187\u001b[0m   \u001b[39m# autodep-like behavior is already expected of fn.\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m    189\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m resource_variables_enabled():\n\u001b[1;32m    190\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(MISSING_RESOURCE_VARIABLES_ERROR)\n",
      "File \u001b[0;32m~/miniforge3/envs/tfagents/lib/python3.11/site-packages/tf_agents/policies/tf_policy.py:560\u001b[0m, in \u001b[0;36mTFPolicy._action\u001b[0;34m(self, time_step, policy_state, seed)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Implementation of `action`.\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \n\u001b[1;32m    547\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[39m    `info`: Optional side information such as action log probabilities.\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    559\u001b[0m seed_stream \u001b[39m=\u001b[39m tfp\u001b[39m.\u001b[39mutil\u001b[39m.\u001b[39mSeedStream(seed\u001b[39m=\u001b[39mseed, salt\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtf_agents_tf_policy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 560\u001b[0m distribution_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_distribution(time_step, policy_state)  \u001b[39m# pytype: disable=wrong-arg-types\u001b[39;00m\n\u001b[1;32m    561\u001b[0m actions \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m    562\u001b[0m     \u001b[39mlambda\u001b[39;00m d: reparameterized_sampling\u001b[39m.\u001b[39msample(d, seed\u001b[39m=\u001b[39mseed_stream()),\n\u001b[1;32m    563\u001b[0m     distribution_step\u001b[39m.\u001b[39maction)\n\u001b[1;32m    564\u001b[0m info \u001b[39m=\u001b[39m distribution_step\u001b[39m.\u001b[39minfo\n",
      "File \u001b[0;32m~/miniforge3/envs/tfagents/lib/python3.11/site-packages/tf_agents/policies/greedy_policy.py:80\u001b[0m, in \u001b[0;36mGreedyPolicy._distribution\u001b[0;34m(self, time_step, policy_state)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYour network\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms distribution does not implement mode \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mmaking it incompatible with a greedy policy.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     76\u001b[0m                     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n\u001b[1;32m     78\u001b[0m   \u001b[39mreturn\u001b[39;00m tfp\u001b[39m.\u001b[39mdistributions\u001b[39m.\u001b[39mDeterministic(loc\u001b[39m=\u001b[39mgreedy_action)\n\u001b[0;32m---> 80\u001b[0m distribution_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wrapped_policy\u001b[39m.\u001b[39;49mdistribution(\n\u001b[1;32m     81\u001b[0m     time_step, policy_state)\n\u001b[1;32m     82\u001b[0m \u001b[39mreturn\u001b[39;00m policy_step\u001b[39m.\u001b[39mPolicyStep(\n\u001b[1;32m     83\u001b[0m     tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(dist_fn, distribution_step\u001b[39m.\u001b[39maction),\n\u001b[1;32m     84\u001b[0m     distribution_step\u001b[39m.\u001b[39mstate, distribution_step\u001b[39m.\u001b[39minfo)\n",
      "File \u001b[0;32m~/miniforge3/envs/tfagents/lib/python3.11/site-packages/tf_agents/policies/tf_policy.py:403\u001b[0m, in \u001b[0;36mTFPolicy.distribution\u001b[0;34m(self, time_step, policy_state)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_automatic_state_reset:\n\u001b[1;32m    402\u001b[0m   policy_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_reset_state(time_step, policy_state)\n\u001b[0;32m--> 403\u001b[0m step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_distribution(time_step\u001b[39m=\u001b[39;49mtime_step, policy_state\u001b[39m=\u001b[39;49mpolicy_state)\n\u001b[1;32m    404\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39memit_log_probability:\n\u001b[1;32m    405\u001b[0m   \u001b[39m# This here is set only for compatibility with info_spec in constructor.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m   info \u001b[39m=\u001b[39m policy_step\u001b[39m.\u001b[39mset_log_probability(\n\u001b[1;32m    407\u001b[0m       step\u001b[39m.\u001b[39minfo,\n\u001b[1;32m    408\u001b[0m       tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m    409\u001b[0m           \u001b[39mlambda\u001b[39;00m _: tf\u001b[39m.\u001b[39mconstant(\u001b[39m0.\u001b[39m, dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32),\n\u001b[1;32m    410\u001b[0m           policy_step\u001b[39m.\u001b[39mget_log_probability(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_spec)))\n",
      "File \u001b[0;32m~/miniforge3/envs/tfagents/lib/python3.11/site-packages/tf_agents/policies/q_policy.py:156\u001b[0m, in \u001b[0;36mQPolicy._distribution\u001b[0;34m(self, time_step, policy_state)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39mif\u001b[39;00m observation_and_action_constraint_splitter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m   network_observation, mask \u001b[39m=\u001b[39m observation_and_action_constraint_splitter(\n\u001b[1;32m    154\u001b[0m       network_observation)\n\u001b[0;32m--> 156\u001b[0m q_values, policy_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_q_network(\n\u001b[1;32m    157\u001b[0m     network_observation, network_state\u001b[39m=\u001b[39;49mpolicy_state,\n\u001b[1;32m    158\u001b[0m     step_type\u001b[39m=\u001b[39;49mtime_step\u001b[39m.\u001b[39;49mstep_type)\n\u001b[1;32m    160\u001b[0m logits \u001b[39m=\u001b[39m q_values\n\u001b[1;32m    162\u001b[0m \u001b[39mif\u001b[39;00m observation_and_action_constraint_splitter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m   \u001b[39m# Overwrite the logits for invalid actions to logits.dtype.min.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tfagents/lib/python3.11/site-packages/tf_agents/networks/network.py:389\u001b[0m, in \u001b[0;36mNetwork.__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"A wrapper around `Network.call`.\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \n\u001b[1;32m    350\u001b[0m \u001b[39mA typical `call` method in a class subclassing `Network` will have a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39m  A tuple `(outputs, new_network_state)`.\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_tensor_spec \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m   nest_utils\u001b[39m.\u001b[39;49massert_matching_dtypes_and_inner_shapes(\n\u001b[1;32m    390\u001b[0m       inputs,\n\u001b[1;32m    391\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_tensor_spec,\n\u001b[1;32m    392\u001b[0m       allow_extra_fields\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    393\u001b[0m       caller\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    394\u001b[0m       tensors_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m`inputs`\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    395\u001b[0m       specs_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m`input_tensor_spec`\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    397\u001b[0m call_argspec \u001b[39m=\u001b[39m tf_inspect\u001b[39m.\u001b[39mgetargspec(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall)\n\u001b[1;32m    399\u001b[0m \u001b[39m# Convert *args, **kwargs to a canonical kwarg representation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tfagents/lib/python3.11/site-packages/tf_agents/utils/nest_utils.py:371\u001b[0m, in \u001b[0;36massert_matching_dtypes_and_inner_shapes\u001b[0;34m(tensors_or_specs, specs, caller, tensors_name, specs_name, allow_extra_fields)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39mif\u001b[39;00m allow_extra_fields:\n\u001b[1;32m    367\u001b[0m   tensors_or_specs \u001b[39m=\u001b[39m prune_extra_keys(specs, tensors_or_specs)\n\u001b[1;32m    368\u001b[0m assert_same_structure(\n\u001b[1;32m    369\u001b[0m     tensors_or_specs,\n\u001b[1;32m    370\u001b[0m     specs,\n\u001b[0;32m--> 371\u001b[0m     message\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m: \u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m and \u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m do not have matching structures\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(\n\u001b[1;32m    372\u001b[0m         caller, tensors_name, specs_name)))\n\u001b[1;32m    374\u001b[0m flat_tensors \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mflatten(tensors_or_specs)\n\u001b[1;32m    375\u001b[0m flat_specs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(specs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# @test {\"skip\": true}\n",
    "try:\n",
    "  % % time\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "for i in range(num_iterations):\n",
    "  print(\"Iteration \", i)\n",
    "\n",
    "  # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "  for _ in range(collect_steps_per_iteration):\n",
    "    collect_step(train_env, agent.collect_policy)\n",
    "\n",
    "  # Sample a batch of data from the buffer and update the agent's network.\n",
    "  experience, unused_info = next(iterator)\n",
    "  print(type(experience))\n",
    "  train_loss = agent.train(experience)\n",
    "\n",
    "  step = agent.train_step_counter.numpy()\n",
    "\n",
    "  if step % log_interval == 0:\n",
    "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "  if step % eval_interval == 0:\n",
    "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "    print('step = {0}: Average Return = {1:.2f}'.format(step, avg_return))\n",
    "    returns.append(avg_return)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (21,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m steps \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, num_iterations \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, eval_interval)\n\u001b[0;32m----> 2\u001b[0m plt\u001b[39m.\u001b[39;49mplot(steps, returns)\n\u001b[1;32m      3\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mAverage Return\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mStep\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tfagents/lib/python3.11/site-packages/matplotlib/pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[1;32m   2811\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2812\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39;49mplot(\n\u001b[1;32m   2813\u001b[0m         \u001b[39m*\u001b[39;49margs, scalex\u001b[39m=\u001b[39;49mscalex, scaley\u001b[39m=\u001b[39;49mscaley,\n\u001b[1;32m   2814\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/tfagents/lib/python3.11/site-packages/matplotlib/axes/_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1685\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[0;32m-> 1688\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[1;32m   1689\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[1;32m   1690\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/miniforge3/envs/tfagents/lib/python3.11/site-packages/matplotlib/axes/_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[1;32m    310\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> 311\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(\n\u001b[1;32m    312\u001b[0m     this, kwargs, ambiguous_fmt_datakey\u001b[39m=\u001b[39;49mambiguous_fmt_datakey)\n",
      "File \u001b[0;32m~/miniforge3/envs/tfagents/lib/python3.11/site-packages/matplotlib/axes/_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39myaxis\u001b[39m.\u001b[39mupdate_units(y)\n\u001b[1;32m    503\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[0;32m--> 504\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y must have same first dimension, but \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhave shapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    506\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    507\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y can be no greater than 2D, but have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (21,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(steps, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Step')\n",
    "plt.ylim(top=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
